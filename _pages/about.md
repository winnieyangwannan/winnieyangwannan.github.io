---
layout: about
title: Home
permalink: /
subtitle: 

profile:
  align: right
  image: prof_pic.png
  image_circular: false # crops the image to make it circular
  more_info: >


news: false # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: ture # includes social icons at the bottom of the page
---
# Wannan (Winnie) Yang
\
&nbsp;

###  Welcome to My Corner of the Web! ðŸ‘‹

I'm Winnie, a PhD candidate at New York University (NYU).


My work spans from biological brains (my works were published in [Science](https://www.science.org/doi/10.1126/science.adk8261) and [Nature](https://www.nature.com/articles/s41586-024-08397-7) to autonomous LLM research agents (current research at Meta). I've spent years understanding biological learning machines and currently building artificial ones. The brain taught me how intelligence works. AI taught me how to build it. Now I want to close this circleâ€”using insights from biological intelligence to build better AI, then wielding that AI to decode biology itself.



### Current Focus
My current interests include:

- **Open-endedness**: Evolving self-improving LLM  Coding Agent using evolutionary algorithm (collaborating with [Jenny Zhang](https://www.jennyzhangzt.com/)) 
- **AI Research Scientist**: In November 2025, I will join the AIRA Team at FAIR (manager: [Yoram Bachrach](https://www.linkedin.com/in/yoram-bachrach-0a03731/?originalSubdomain=uk)), building toward a fully automated AI research scientist.  

### Past Research Hilight
In early 2024 I was beginning my transition from Neuroscience to AI. By then, progress in AI for several years had already exploded in a myriad of promise and hope. But what struck me in 2024 was that the **rate** of progress was continuing unabated, and my feelings of open-ended benefit for humanity turned to worries for our extinction as we barrel unprepared toward the direction of ASI. My main motivation is that in order for humanity to benefit from the plethora of benefits that AI brings, we _must make sure the system is aligned_, and we must build such safe systems **now**.

Within the broad goal of helping superalignment, my have conducted research revolve around building automated alignment research assistants -- perhaps by better leveraging interpretability tools to monitor their internals.  

One area, for instance, that I have worked on is to monitor/evaluate the trustworthiness/deception of both alignment assistant (supervisor) and the supervisee via interpretability tools ([Preprint](http://localhost:8080/projects/3_project/)). 

Using interpretability insight, I have devellped an effiicient post-training agorithm to reduce hallucination in LLMs ([Preprint](https://arxiv.org/pdf/2510.02324)).


Delving into the black box is within my existing expertise as a neuroscientist (expertise in â€˜internal oversightâ€™ of the brain) as well as my recent research experience in LLM deception. 

---


## *NEWS*{: style="color: #5663b0;" }


#####  *- [2025-10-18]: I will start my new role as a student researcher at Meta FAIR in November 2025. I will work on building AI Research Agent with  [Yoram Bachrach](https://www.linkedin.com/in/yoram-bachrach-0a03731/?originalSubdomain=uk). ðŸ¥³*{: style="color: #5663b0;" }

#####  *- [2025-09-22]: Our Hallucination Reduction paper was published in [MI NeurIPS](https://openreview.net/pdf?id=t7zE9rOWHl). ðŸŽ‰*{: style="color: #5663b0;" }

#####  *- [2025-01-08]: Our paper titled "Hippocampal neuronal activity is aligned with action plans" was published in [Nature](https://www.nature.com/articles/s41586-024-08397-7). ðŸŽŠ*{: style="color: #5663b0;" }



#####  *- [2024-10-12]: Our 'LLM lying' paper was accepted at the SafeGenAi workshop at [NeurIPS](https://winnieyangwannan.github.io/LLM_Deception/). ðŸŽ‰*{: style="color: #5663b0;" }


#####  *- [2024-05-21]: Our 'ripple-tagging' paper was covered in the [Quanta Magzine](https://www.quantamagazine.org/electric-ripples-in-the-resting-brain-tag-memories-for-storage-20240521/).*{: style="color: #5663b0;" }



#####  *- [2024-03-28]: Our 'ripple-tagging' paper was published in [Science](https://www.science.org/doi/10.1126/science.adk8261).ðŸŽ‰*{: style="color: #5663b0;" }
